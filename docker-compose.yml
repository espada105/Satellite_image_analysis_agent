services:
  mcp:
    build:
      context: .
      dockerfile: Dockerfile.mcp
    env_file:
      - .env
    environment:
      - LOG_LEVEL=INFO
      - LOG_JSON=true
    volumes:
      - ./data:/app/data
    restart: unless-stopped

  orchestrator:
    build:
      context: .
      dockerfile: Dockerfile.orchestrator
    env_file:
      - .env
    environment:
      - HF_HOME=/app/models
      - MCP_BASE_URL=http://mcp:8100
      - VERIFIED_USER_IDS=${VERIFIED_USER_IDS}
      - LLM_API_KEY=${LLM_API_KEY}
      - LLM_MODEL=${LLM_MODEL:-gpt-4o-mini}
      - LLM_BASE_URL=${LLM_BASE_URL:-https://api.openai.com/v1}
      - RATE_LIMIT_ENABLED=true
      - RATE_LIMIT_REQUESTS=120
      - RATE_LIMIT_WINDOW_SECONDS=60
      - ENABLE_METRICS=true
      - LOG_LEVEL=INFO
      - LOG_JSON=true
    depends_on:
      - mcp
    ports:
      - "8000:8000"
    volumes:
      - ./data:/app/data
      - ./models:/app/models
    restart: unless-stopped
